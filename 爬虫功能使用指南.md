# 🕷️ 新闻爬虫功能使用指南

## 📋 功能概述

系统集成了智能新闻爬虫功能，可以自动从多个新闻源采集最新新闻，并自动完成以下任务：
- ✅ 采集最新新闻内容
- ✅ 自动去重（避免重复采集）
- ✅ 智能分类（基于关键词规则）
- ✅ 自动保存到数据库

---

## 🌐 支持的新闻源

目前系统支持以下新闻源：

| 新闻源 | 描述 | 代码标识 |
|--------|------|---------|
| 📺 **CCTV新闻** | 中央电视台官方新闻 | `cctv` |
| 📰 **新浪新闻** | 新浪网新闻资讯 | `sina` |
| 📱 **网易新闻** | 网易新闻频道 | `netease` |

---

## 🎯 使用方式

### 方式一：通过管理后台界面（推荐）

#### 1️⃣ 登录管理后台
```
访问：http://localhost:5173/login
账号：admin
密码：admin123
```

#### 2️⃣ 进入爬虫管理页面
```
点击左侧菜单："采集管理"
或直接访问：http://localhost:5173/admin/crawler
```

#### 3️⃣ 测试爬虫连接
点击 **"🔍 测试所有连接"** 按钮，系统会检测所有新闻源是否可用

#### 4️⃣ 启动采集任务

**选项A - 采集单个新闻源：**
1. 在"可用新闻源"表格中找到要采集的源
2. 设置采集数量（5-50条）
3. 点击对应的 **"启动采集"** 按钮

**选项B - 采集所有新闻源：**
1. 点击顶部的 **"🚀 启动所有爬虫"** 按钮
2. 系统会同时从所有源采集新闻

#### 5️⃣ 查看采集结果
- 采集任务在后台异步执行
- 等待几秒后，点击 **"刷新统计"** 或 **"刷新"** 查看结果
- 在"采集历史"中可以看到任务状态
- 前往"新闻管理"页面查看采集到的新闻

---

### 方式二：通过API接口

如果您想通过代码或测试工具（如Postman）调用爬虫：

#### 🔐 先获取登录Token
```bash
POST http://localhost:8080/api/auth/login
Content-Type: application/json

{
  "username": "admin",
  "password": "admin123"
}
```

返回的 `token` 需要在后续请求中使用。

#### 📡 触发单个爬虫
```bash
POST http://localhost:8080/api/crawler/trigger/{source}?maxCount=10
Authorization: Bearer {你的token}
```

**示例：**
```bash
# 采集 CCTV 新闻（10条）
POST http://localhost:8080/api/crawler/trigger/cctv?maxCount=10

# 采集新浪新闻（20条）
POST http://localhost:8080/api/crawler/trigger/sina?maxCount=20

# 采集网易新闻（15条）
POST http://localhost:8080/api/crawler/trigger/netease?maxCount=15
```

#### 🚀 触发所有爬虫
```bash
POST http://localhost:8080/api/crawler/trigger/all?maxCount=10
Authorization: Bearer {你的token}
```

#### 📊 查看可用的爬虫源
```bash
GET http://localhost:8080/api/crawler/sources
Authorization: Bearer {你的token}
```

#### 🧪 测试爬虫连接
```bash
GET http://localhost:8080/api/crawler/test
Authorization: Bearer {你的token}
```

#### 📜 查看采集历史
```bash
GET http://localhost:8080/api/crawler/tasks?limit=20
Authorization: Bearer {你的token}
```

#### 📈 查看统计信息
```bash
GET http://localhost:8080/api/crawler/statistics
Authorization: Bearer {你的token}
```

---

### 方式三：使用PowerShell脚本

我已经为您准备了测试脚本！

#### 查看可用脚本
```powershell
# 查看项目根目录
ls *.ps1

# 应该能看到：
# - test_crawler_api.ps1
# - test_news_api.ps1
# - test_summary_api.ps1
```

#### 使用爬虫测试脚本
```powershell
# 运行爬虫测试脚本
.\test_crawler_api.ps1
```

---

## ⚙️ 参数说明

### maxCount（采集数量）
- **范围**：5-50
- **默认值**：10
- **说明**：每次采集获取的新闻数量
- **建议**：
  - 测试时用 5-10
  - 正式使用 20-30
  - 最多不超过 50（避免过载）

---

## 🔄 自动采集任务

系统还支持定时自动采集（需要在后端配置）：

### 查看定时任务配置
文件位置：`backend/src/main/java/com/news/scheduler/NewsCrawlerScheduler.java`

### 默认配置
- **频率**：每4小时执行一次
- **时间**：凌晨0点、4点、8点、12点、16点、20点
- **数量**：每次每个源采集10条

### 启用/禁用定时任务
在 `NewsCrawlerScheduler.java` 中：
```java
// 注释掉 @Scheduled 注解可以禁用定时任务
// @Scheduled(cron = "0 0 */4 * * ?")
public void scheduledCrawl() {
    // ...
}
```

---

## 📊 采集结果说明

### 任务状态
- **PENDING** - 待执行
- **RUNNING** - 运行中
- **SUCCESS** - 成功完成
- **FAILED** - 执行失败

### 成功计数
- **成功数**：成功保存的新闻数量
- **失败数**：采集失败或重复的数量

### 常见情况
- 如果"失败数"较多，可能是因为新闻已经存在（去重）
- 首次采集成功率最高
- 后续采集会因为去重导致成功数减少

---

## ⚠️ 注意事项

### 1. 采集频率
- ⚠️ 不要频繁采集同一个源（建议间隔至少10分钟）
- ⚠️ 尊重新闻源网站，避免造成负担
- ⚠️ 生产环境建议降低采集频率

### 2. 去重机制
- ✅ 系统会自动检查标题重复
- ✅ 如果URL相同也会跳过
- ✅ 重复的新闻不会被保存

### 3. 自动分类
- ✅ 采集的新闻会自动分类
- ✅ 分类基于关键词规则（在"分类规则"中配置）
- ✅ 如果匹配不到规则，会分到默认分类

### 4. 性能考虑
- 采集任务是异步执行的
- 多个任务可以同时进行
- 不会阻塞主线程和用户请求

---

## 🧪 快速测试

### 测试流程
```bash
# 1. 确保所有服务已启动
.\start_system.bat

# 2. 访问管理后台
浏览器打开：http://localhost:5173/login

# 3. 登录
用户名：admin
密码：admin123

# 4. 进入爬虫管理
点击左侧"采集管理"

# 5. 测试连接
点击"🔍 测试所有连接"

# 6. 启动单个爬虫
在CCTV新闻行，设置数量为5，点击"启动采集"

# 7. 等待5-10秒后刷新页面

# 8. 查看结果
前往"新闻管理"页面，应该能看到新采集的新闻
```

---

## 📈 查看采集的新闻

### 在管理后台查看
```
http://localhost:5173/admin/news
```

### 在前台查看
```
http://localhost:5173/
```

### 通过API查看
```bash
GET http://localhost:8080/api/news?page=0&size=20
```

---

## 🔧 故障排除

### 问题：测试连接显示"离线"
**可能原因：**
- 网络连接问题
- 新闻源网站暂时不可访问
- 防火墙阻止

**解决方案：**
- 检查网络连接
- 稍后重试
- 尝试其他新闻源

### 问题：采集任务失败
**可能原因：**
- 网站结构变化
- 网络超时
- 爬虫被封禁

**解决方案：**
- 查看"采集历史"中的错误信息
- 检查后端日志：`backend/logs/news-management.log`
- 降低采集频率

### 问题：采集成功但没有新闻
**可能原因：**
- 所有新闻都是重复的（已存在）
- 失败数 = 采集数

**解决方案：**
- 这是正常情况，说明数据已经是最新的
- 等待一段时间后再试

### 问题：401 Unauthorized
**可能原因：**
- 未登录或token过期

**解决方案：**
- 重新登录
- 检查token是否正确传递

---

## 📞 常用链接

| 功能 | 链接 |
|------|------|
| 🔑 登录 | http://localhost:5173/login |
| 🕷️ 爬虫管理 | http://localhost:5173/admin/crawler |
| 📰 新闻管理 | http://localhost:5173/admin/news |
| 🏠 前台首页 | http://localhost:5173/ |
| 🔌 API根地址 | http://localhost:8080/api |

---

## 🎉 开始使用

**最简单的方式：**
1. 访问 http://localhost:5173/login
2. 登录（admin / admin123）
3. 点击"采集管理"
4. 点击"🚀 启动所有爬虫"
5. 等待10秒
6. 前往"新闻管理"查看结果

就这么简单！🚀

---

## 💡 提示

- 首次使用建议先测试单个新闻源
- 采集数量从小到大逐步增加
- 定期查看采集历史，了解系统运行状况
- 如果某个源长期失败，可以暂时停用
- 配合"智能摘要"功能，体验更佳！

